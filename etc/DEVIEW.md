# DEVIEW 2023

<!-- TOC -->

- [DEVIEW 2023](#deview-2023)
  - [DAY 1](#day-1)
    - [네이버 검색은 어떻게 나보다 내 의도를 잘 아는가? : AiRSearch 반응형 추천](#%EB%84%A4%EC%9D%B4%EB%B2%84-%EA%B2%80%EC%83%89%EC%9D%80-%EC%96%B4%EB%96%BB%EA%B2%8C-%EB%82%98%EB%B3%B4%EB%8B%A4-%EB%82%B4-%EC%9D%98%EB%8F%84%EB%A5%BC-%EC%9E%98-%EC%95%84%EB%8A%94%EA%B0%80--airsearch-%EB%B0%98%EC%9D%91%ED%98%95-%EC%B6%94%EC%B2%9C)
    - [바닥까지 파보는! Hbase random read 성능 개선기](#%EB%B0%94%EB%8B%A5%EA%B9%8C%EC%A7%80-%ED%8C%8C%EB%B3%B4%EB%8A%94-hbase-random-read-%EC%84%B1%EB%8A%A5-%EA%B0%9C%EC%84%A0%EA%B8%B0)
    - [네이버 스케일로 카프카 컨슈머 사용하기](#%EB%84%A4%EC%9D%B4%EB%B2%84-%EC%8A%A4%EC%BC%80%EC%9D%BC%EB%A1%9C-%EC%B9%B4%ED%94%84%EC%B9%B4-%EC%BB%A8%EC%8A%88%EB%A8%B8-%EC%82%AC%EC%9A%A9%ED%95%98%EA%B8%B0)
    - [SCDF로 하루 N만곡 이상 VIBE 메타 데이터 실시간으로 적재하기](#scdf%EB%A1%9C-%ED%95%98%EB%A3%A8-n%EB%A7%8C%EA%B3%A1-%EC%9D%B4%EC%83%81-vibe-%EB%A9%94%ED%83%80-%EB%8D%B0%EC%9D%B4%ED%84%B0-%EC%8B%A4%EC%8B%9C%EA%B0%84%EC%9C%BC%EB%A1%9C-%EC%A0%81%EC%9E%AC%ED%95%98%EA%B8%B0)
  - [DAY 2](#day-2)
    - [ML/AI 개발자를 위한 단계별 Python 최적화 가이드라인](#mlai-%EA%B0%9C%EB%B0%9C%EC%9E%90%EB%A5%BC-%EC%9C%84%ED%95%9C-%EB%8B%A8%EA%B3%84%EB%B3%84-python-%EC%B5%9C%EC%A0%81%ED%99%94-%EA%B0%80%EC%9D%B4%EB%93%9C%EB%9D%BC%EC%9D%B8)
    - [런타임 데드 코드 분석 도구 Scavenger - 당신의 코드는 생각보다 많이 죽어있다.](#%EB%9F%B0%ED%83%80%EC%9E%84-%EB%8D%B0%EB%93%9C-%EC%BD%94%EB%93%9C-%EB%B6%84%EC%84%9D-%EB%8F%84%EA%B5%AC-scavenger---%EB%8B%B9%EC%8B%A0%EC%9D%98-%EC%BD%94%EB%93%9C%EB%8A%94-%EC%83%9D%EA%B0%81%EB%B3%B4%EB%8B%A4-%EB%A7%8E%EC%9D%B4-%EC%A3%BD%EC%96%B4%EC%9E%88%EB%8B%A4)
    - [값비싼 Diffusion model 을 받드는 저비용 MLOps](#%EA%B0%92%EB%B9%84%EC%8B%BC-diffusion-model-%EC%9D%84-%EB%B0%9B%EB%93%9C%EB%8A%94-%EC%A0%80%EB%B9%84%EC%9A%A9-mlops)

<!-- /TOC -->

<br>

## DAY 1

### 네이버 검색은 어떻게 나보다 내 의도를 잘 아는가? : AiRSearch 반응형 추천

> AiRSearch 반응형 추천이란 사용자가 통합검색을 통해 문서를 검색하고 해당 문서를 읽고 되돌아 왔을 때, 읽은 문서를 기반으로 관련도가 높은 문서를 추천해주는 기능이다.

반응형 추천 문제를 풀기위해 어떻게 input 데이터를 추출하고 추출한 데이터를 기반으로 어떻게 사용자의 문서 재소비를 높힐 수 있을 지 고민한 내용에 대한 발표였다.
input 데이터는 사용자의 검색어, 검색으로 추천된 문서 중 사용자가 클릭한 문서, 사용자의 취향 정보를 바탕으로 추출했다. 검색어와 문서를 통해 사용자가 원하는 키워드를 Narrow-Down 방식으로 좁혀나갔고, 이 키워드와 관련도가 높은 문서를 우선순위로 추천되는 기능이다.
해당 발표를 통해 우리가 주로 이용하는 네이버에서 어떤 데이터를 기반으로 사용자에게 새로운 문서를 추천해주는지 알 수 있었고, 우리의 행동 하나하나가 데이터로 사용되고 유의미한 결과를 추출하는데 사용된다는 것을 깨달았다.

<br>

### 바닥까지 파보는! Hbase random read 성능 개선기

> Naver Data 저장플랫폼인 CUVE 는 HBase 기반 범용적인 대규모 분산 데이터 저장소이다.

CUVE 는 검색 데이터 저장소이다 보니 다양한 데이터를 보관할 수 있는 범용성과 많은 데이터를 보관할 수 있는 대규모 두가지 특성을 만족해야 한다.
효율적인 클러스터 운영을 위해서

1. 제약 을 두게되면 안정성과 효율성은 올라가는 반면, 사용성과 범용성이 감소하게 된다.

다른 방법으로 Multi-clustered storage 와 HBase 데이터 유연성 개선 방법이 있다.

2. Multi-clustered storage 방법은 여러 종류의 데이터와 사용패턴을 일정 수준이상의 규모로 모아 클러스터를 구분하고 각각의 데이터에 맞게 최적화 하는 방법이다. 이 방법은 안정성, 효율성, 범용성 에 모두 만족하지만, 여러개의 클러스터를 사용하다보니 개발,운영비용이 증가하고 확장성이 떨어지게 된다.

3. HBase 의 구조를 깊게 파고들어 데이터 유연성을 개선하는 방법으로 단기적인 분석, 개발비용의 증가를 제외하면 모든 부분에서 효과적이라고 생각했다.

- 여기서 발생하는 문제는 HBase random read amplification 이다.
  - HBase 의 random read 과정에서 Client 가 실제 쿼리한 data size 보다 증폭된 hdfs read 요청, 그 결과로 과도한 disk IO 사용
    이 원인에는 세가지가 있다.

1. Multi File Access Amplification
2. Granularity Mismatch Amplification
3. Cache Pollution

발표에서 각각의 원인이 맞는지 검증하고, 해결하는 과정을 통해 DB 의 동작원리, DB 의 구조에 대해 심도있게 알아야 저렇게 효율적으로 데이터를 적재하고 활용할 수 있다는 것을 깨달았다.

<br>

### 네이버 스케일로 카프카 컨슈머 사용하기

> 사내 Kafka 서비스 개발팀에서 네이버 스케일로 Kafka Consumer 사용방법에 대해 설명하는 발표

Kafka 동작원리부터 시작해서 Cloud, 네이버 스케일에서 Kafka Consumer 를 효율적으로 사용하는 방법을 알 수 있었다. Kafka 의 동작원리에 대해 처음으로 배울 수 있었고, Kafka 를 여러 팀에서 기술스택으로 사용하고 있다는 것을 알게되었다. Partition, Replica 와 같은 용어들이 많이 나왔는데 단어에 대한 기본개념이 없어서 이해하는데 어려움이 있었다. Database 학습이 필요하다고 느꼈다.

<br>

### SCDF로 하루 N만곡 이상 VIBE 메타 데이터 실시간으로 적재하기

> VIBE 에서 하루에 몇십만곡 이상씩 데이터를 적재할 수 있었던 방법에 대한 발표

- 대용량 데이터를 처리하는 방식에 대해 설명해줬다.
  - 대량의 데이터를 일괄처리 (Batch)
  - 무한한 데이터를 실시간처리 (Stream)

두가지 방식이 있는데, 상황에 따라 데이터를 처리하는 방식을 선택해야 한다.
배치처리는 데이터를 한번에 처리하는 경우 (누적데이터), 스트림처리는 데이터를 수집하거나 저장하지않고 데이터가 지속적으로 유입되는 경우 (실시간데이터) 사용한다.

- 데이터를 더 빠르게 처리하는 기법

  - 부하 분산
  - 파티셔닝
  - 워크플로 매니지먼트 (= Airflow, Spring Cloud Data Flow)

- 더 많은 데이터를 적재하기 위한 고민
  - 현재 시스템의 개발/운영 하는 방식에 어떤문제점이있는가?
  - 새롭게 개발하면서 우리가 얻고자 하는 가치는 무엇인가?
  - 어떠한 기준을 가장 우선 순위에 두고 아키텍처를 설계 할 것인가?
  - 어떤 데이터 저장소를 사용하는게 적합한 것인가?
  - 어떤 구현방식으로 개발해서 구축할 것인가?

이렇게 고민하는 과정을 보면서 정말 다양한 관점에서 자원을 효율적으로 사용하기 위해 고민해야 하고 설계, 아키텍처, 기술스택 선택의 중요성에 대해 다시 한번 생각해볼 수 있는 계기가 되었다.

<br>

## DAY 2

### ML/AI 개발자를 위한 단계별 Python 최적화 가이드라인

> 파파고 이미지 번역과정에서 느린 Python 속도때문에 이미지 실시간 번역 시 너무 오래걸리는 문제를 해결하기 위해 Python 최적화를 진행했다.

Python 코드를 최적화하는 여러가지 방법들을 단계별로 설명해주었다.

우선 코드에서 병목현상이 발생하는 곳을 파악하기 위해 Line Profiler 라는 가장 쉽게 접근할 수 있는 프로파일러를 사용하였다.

두번째는 같은 출력을 내는 여러가지 문법을 비교해서 시간복잡도가 더 빠른 코드를 사용해보자.

세번째는 C 언어로 만들어진 라이브러리를 사용하는 방법이다. C 로 만들어진 라이브러리는 Python 코드보다 훨씬 빠르기 때문에 속도를 대폭 개선할 수 있다. 다만 C/C++ 기반 외부 패키지를 많이 사용하는 경우, CPython 을 사용할 경우 오히려 오버헤드가 증가할 수 있다.

내용이 엄청 유용하진 않았지만, 흥미로운 강의였다. 응답시간 최적화를 위해 다양한 방법을 시도하고 개발에 푹빠져서 즐기는 사람들을 보며 개발에 대한 열정이 높힐 수 있었다.

<br>

### 런타임 데드 코드 분석 도구 Scavenger - 당신의 코드는 생각보다 많이 죽어있다.

> Scavenger 란 Naver 에서 개발한 오픈소스기반 런타임 코드분석도구이다.

Dead Code 란 실행되지않는 코드, 실행되더라도 애플리케이션 동작에 영향을 미치지 않는 코드를 칭한다. Dead Code 는 코드의 가독성을 낮추고, 코드끼리 플래그를 형성할 경우 애플리케이션에 부정적인 영향을 줄 수 있다.
Scavenger 는 Naver 에서 런타임 중에 코드를 분석할 수 있도록 개발한 툴이다.
아키텍처를 직접 설계하고 Java Agent 를 사용하여 개발하였는데, 기본 설정으로 사용하는 클래스 파일 구조를 보고 느낀점이 많았다. 비트단위로 구성된 클래스 파일을 직접 설계하고 개발했다는 것을 듣고, Computer Science 와 같은 Low level 지식을 학습하는 것이 굉장히 중요하다는 것을 깨닫게 되었다. 다양한 프레임워크가 나오고 생태계가 바뀌더라도 CS 는 변하지 않는다.

<br>

### 값비싼 Diffusion model 을 받드는 저비용 MLOps

> 굉장히 빠르게 발전하는 AI 이미지 생성기술의 용어와 변화과정을 알 수 있었다.

Diffusion is Multimodal Image Generation with diffusion process

- Multimodal

  - Singlemodal 이란 단일 유형의 입력으로 이미지를 생성하는 방식
  - Multimodal 이란 두개 이상의 유형의 입력으로 이미지를 생성하는 방식
    - ex) 이미지와 텍스트 입력으로 이미지를 생성하는 방법

- Diffusion process
  - 기존 GAN 방식 : 실제 데이터와 구별할 수 없는 합성 데이터를 한번에 생성
  - Diffusion : 확률 모델과 확산 프로세스를 사용하여 원래 분포에 근사한 합성데이터를 생성
    - 노이즈가 섞인 형태를 생성하고 반복적으로 denoising 을 통해 더 뚜렷한 이미지를 생성한다.

diffusion model 은 6개월간에 22.08 논문을 발표로 급격하게 성장하고있다. 점점더 작은 데이터와 denosing 의 적은 반복으로 뚜렷한 결과물을 만들 수 있도록 발전하고있다. 해당 발표를 통해서 Image Generation AI 와 관련된 용어와 방식의 차이에 대해 학습할 수 있었고, 흥미를 갖는 계기가 되었다.
